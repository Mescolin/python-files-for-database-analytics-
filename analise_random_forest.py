import pandas as pd
import numpy as np
import warnings
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import chi2_contingency
import time

# Scikit-learn imports
from sklearn.model_selection import (
    train_test_split, GridSearchCV, RandomizedSearchCV, 
    StratifiedKFold, cross_val_score, validation_curve
)
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    classification_report, confusion_matrix, roc_auc_score, roc_curve,
    precision_recall_curve, auc, matthews_corrcoef, balanced_accuracy_score,
    fbeta_score, accuracy_score, precision_score, recall_score,
    average_precision_score, log_loss
)
from sklearn.inspection import permutation_importance
from sklearn.utils.class_weight import compute_class_weight

# Otimiza√ß√£o bayesiana
try:
    from skopt import BayesSearchCV
    from skopt.space import Real, Integer, Categorical
    BAYESIAN_AVAILABLE = True
except ImportError:
    print("AVISO: Biblioteca skopt n√£o encontrada. Usando GridSearchCV padr√£o.")
    BAYESIAN_AVAILABLE = False

# Configura√ß√µes globais
warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("husl")
pd.set_option('display.max_columns', None)
np.random.seed(42)

print("Sistema de Predi√ß√£o de Attrition - TechCorp Brasil")
print("=" * 60)

class AttritionAnalyzer:
    """
    Classe principal para an√°lise e predi√ß√£o de attrition de funcion√°rios.
    
    Esta classe implementa um pipeline completo de machine learning incluindo:
    - An√°lise explorat√≥ria detalhada
    - Pr√©-processamento inteligente dos dados
    - M√∫ltiplos algoritmos de classifica√ß√£o
    - Otimiza√ß√£o de hiperpar√¢metros
    - Avalia√ß√£o robusta com m√©tricas espec√≠ficas para desbalanceamento
    """
    
    def __init__(self, data_path='WA_Fn-UseC_-HR-Employee-Attrition.csv'):
        self.data_path = data_path
        self.df_raw = None
        self.df = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.models = {}
        self.results = {}
        self.feature_names = None
        
    def load_data(self):
        """Carrega e faz valida√ß√£o inicial dos dados com limpeza autom√°tica."""
        try:
            self.df_raw = pd.read_csv(self.data_path)
            
            # Verificar se h√° problema de header duplicado
            first_row = self.df_raw.iloc[0]
            header_in_data = any(str(value) == col for col, value in first_row.items())
            
            if header_in_data:
                print("AVISO: Header duplicado detectado - aplicando limpeza autom√°tica...")
                # Remover linha com header duplicado
                self.df_raw = self.df_raw[self.df_raw.iloc[:, 0] != self.df_raw.columns[0]].copy()
                
                # Converter colunas num√©ricas
                numeric_columns = ['Age', 'DailyRate', 'DistanceFromHome', 'Education', 
                                  'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',
                                  'PercentSalaryHike', 'TotalWorkingYears', 'TrainingTimesLastYear',
                                  'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 
                                  'YearsWithCurrManager', 'EmployeeNumber', 'HourlyRate',
                                  'JobLevel', 'StockOptionLevel', 'EmployeeCount', 'StandardHours',
                                  'EnvironmentSatisfaction', 'JobInvolvement', 'JobSatisfaction',
                                  'PerformanceRating', 'RelationshipSatisfaction', 'WorkLifeBalance']
                
                for col in numeric_columns:
                    if col in self.df_raw.columns:
                        self.df_raw[col] = pd.to_numeric(self.df_raw[col], errors='coerce')
                
                print("Limpeza autom√°tica conclu√≠da!")
            
            self.df = self.df_raw.copy()
            print(f"Dataset carregado com sucesso!")
            print(f"Dimens√µes: {self.df.shape[0]} funcion√°rios, {self.df.shape[1]} vari√°veis")
            
            # Verifica√ß√£o de qualidade dos dados
            missing_values = self.df.isnull().sum().sum()
            duplicates = self.df.duplicated().sum()
            
            if missing_values > 0:
                print(f"AVISO: {missing_values} valores ausentes detectados")
            if duplicates > 0:
                print(f"AVISO: {duplicates} registros duplicados detectados")
                
            return True
        except FileNotFoundError:
            print(f"ERRO: Arquivo '{self.data_path}' n√£o encontrado.")
            return False
        except Exception as e:
            print(f"ERRO: Erro ao carregar dados: {str(e)}")
            return False
    
    def exploratory_data_analysis(self):
        print("\nAN√ÅLISE EXPLORAT√ìRIA DOS DADOS")
        print("=" * 50)
        
        # Informa√ß√µes b√°sicas do dataset
        self._display_basic_info()
        
        # An√°lise da vari√°vel target
        self._analyze_target_variable()
        
        # An√°lise de vari√°veis num√©ricas
        self._analyze_numerical_variables()
        
        # An√°lise de vari√°veis categ√≥ricas
        self._analyze_categorical_variables()
        
        # An√°lise de correla√ß√µes
        self._correlation_analysis()
        
        # Detec√ß√£o de outliers
        self._outlier_detection()
        
        # Insights de neg√≥cio
        self._business_insights()
    
    def _display_basic_info(self):
        print("\nINFORMA√á√ïES GERAIS")
        print("-" * 30)
        print(f"Total de funcion√°rios: {self.df.shape[0]:,}")
        print(f"Vari√°veis dispon√≠veis: {self.df.shape[1]}")
        
        # Verificar valores nulos
        missing_data = self.df.isnull().sum()
        if missing_data.sum() == 0:
            print("Nenhum valor ausente encontrado")
        else:
            print(f"AVISO: Valores ausentes: {missing_data.sum()}")
        
        # Verificar duplicatas
        duplicates = self.df.duplicated().sum()
        if duplicates == 0:
            print("Nenhuma linha duplicada encontrada")
        else:
            print(f"AVISO: Linhas duplicadas: {duplicates}")
        
        # Tipos de dados
        print(f"Vari√°veis num√©ricas: {self.df.select_dtypes(include=[np.number]).shape[1]}")
        print(f"Vari√°veis categ√≥ricas: {self.df.select_dtypes(include=['object']).shape[1]}")
    
    def _analyze_target_variable(self):
        print("\nAN√ÅLISE DA VARI√ÅVEL TARGET (ATTRITION)")
        print("-" * 45)
        
        # Distribui√ß√£o da vari√°vel target
        attrition_counts = self.df['Attrition'].value_counts()
        attrition_pct = self.df['Attrition'].value_counts(normalize=True) * 100
        
        print("Distribui√ß√£o de Attrition:")
        for category, count in attrition_counts.items():
            pct = attrition_pct[category]
            print(f"{category}: {count:,} funcion√°rios ({pct:.1f}%)")
        
        # C√°lculo do desbalanceamento
        minority_class = attrition_counts.min()
        majority_class = attrition_counts.max()
        imbalance_ratio = majority_class / minority_class
        print(f"\nTaxa de desbalanceamento: {imbalance_ratio:.1f}:1")
        
        if imbalance_ratio > 3:
            print("AVISO: Dataset significativamente desbalanceado - requer tratamento especial")
        
        # Visualiza√ß√£o
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        
        # Gr√°fico de barras
        attrition_counts.plot(kind='bar', ax=ax1, color=['lightblue', 'coral'])
        ax1.set_title('Distribui√ß√£o de Attrition', fontsize=14, fontweight='bold')
        ax1.set_ylabel('N√∫mero de Funcion√°rios')
        ax1.tick_params(axis='x', rotation=0)
        
        # Gr√°fico de pizza
        ax2.pie(attrition_counts.values, labels=attrition_counts.index, autopct='%1.1f%%', 
                colors=['lightblue', 'coral'], startangle=90)
        ax2.set_title('Propor√ß√£o de Attrition', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        plt.show()
    
    def _analyze_numerical_variables(self):
        print("\nAN√ÅLISE DE VARI√ÅVEIS NUM√âRICAS")
        print("-" * 35)
        
        numerical_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()
        
        # Remover colunas constantes ou identificadores
        cols_to_remove = ['EmployeeCount', 'StandardHours', 'EmployeeNumber']
        numerical_cols = [col for col in numerical_cols if col not in cols_to_remove]
        
        print(f"Analisando {len(numerical_cols)} vari√°veis num√©ricas...")
        
        # Estat√≠sticas descritivas
        desc_stats = self.df[numerical_cols].describe()
        print("\nEstat√≠sticas Descritivas (Resumo):")
        print(desc_stats.round(2))
        
        # An√°lise de distribui√ß√µes por attrition
        key_vars = ['Age', 'MonthlyIncome', 'YearsAtCompany', 'TotalWorkingYears', 
                   'DistanceFromHome', 'YearsSinceLastPromotion']
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        axes = axes.ravel()
        
        for i, var in enumerate(key_vars[:6]):
            if var in self.df.columns:
                # Box plot por categoria de attrition
                sns.boxplot(data=self.df, x='Attrition', y=var, ax=axes[i])
                axes[i].set_title(f'Distribui√ß√£o de {var} por Attrition', fontweight='bold')
                axes[i].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        # Teste estat√≠stico para diferen√ßas entre grupos
        self._statistical_tests_numerical(numerical_cols)
    
    def _statistical_tests_numerical(self, numerical_cols):
        print("\nTESTES ESTAT√çSTICOS (Mann-Whitney U)")
        print("-" * 40)
        
        from scipy.stats import mannwhitneyu
        
        significant_vars = []
        
        for var in numerical_cols[:10]:  # Analisar as 10 principais
            if var in self.df.columns:
                group_no = self.df[self.df['Attrition'] == 'No'][var]
                group_yes = self.df[self.df['Attrition'] == 'Yes'][var]
                
                # Teste Mann-Whitney U (n√£o-param√©trico)
                statistic, p_value = mannwhitneyu(group_no, group_yes, alternative='two-sided')
                
                if p_value < 0.05:
                    significant_vars.append(var)
                    significance = "***" if p_value < 0.001 else "**" if p_value < 0.01 else "*"
                    print(f"{var}: p-value = {p_value:.4f} {significance}")
        
        print(f"\n{len(significant_vars)} vari√°veis com diferen√ßas estatisticamente significativas")
    
    def _analyze_categorical_variables(self):
        print("\nAN√ÅLISE DE VARI√ÅVEIS CATEG√ìRICAS")
        print("-" * 38)
        
        categorical_cols = self.df.select_dtypes(include=['object']).columns.tolist()
        categorical_cols.remove('Attrition')  # Remover a vari√°vel target
        
        print(f"Analisando {len(categorical_cols)} vari√°veis categ√≥ricas...")
        
        # An√°lise de associa√ß√£o com chi-quadrado
        significant_associations = []
        
        for var in categorical_cols:
            contingency_table = pd.crosstab(self.df[var], self.df['Attrition'])
            chi2, p_value, dof, expected = chi2_contingency(contingency_table)
            
            if p_value < 0.05:
                significant_associations.append((var, p_value))
        
        significant_associations.sort(key=lambda x: x[1])
        
        print(f"\nVari√°veis com associa√ß√£o significativa (p < 0.05):")
        for var, p_val in significant_associations[:8]:
            significance = "***" if p_val < 0.001 else "**" if p_val < 0.01 else "*"
            print(f"{var}: p-value = {p_val:.4f} {significance}")
        
        # Visualiza√ß√£o das principais vari√°veis categ√≥ricas
        if len(significant_associations) > 0:
            self._plot_categorical_analysis(significant_associations[:4])
    
    def _plot_categorical_analysis(self, top_vars):
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        axes = axes.ravel()
        
        for i, (var, _) in enumerate(top_vars):
            if i < 4:
                # Criar tabela de conting√™ncia percentual
                ct = pd.crosstab(self.df[var], self.df['Attrition'], normalize='index') * 100
                ct.plot(kind='bar', ax=axes[i], stacked=False, 
                       color=['lightblue', 'coral'], alpha=0.8)
                axes[i].set_title(f'Taxa de Attrition por {var}', fontweight='bold')
                axes[i].set_ylabel('Porcentagem (%)')
                axes[i].legend(title='Attrition', bbox_to_anchor=(1.05, 1), loc='upper left')
                axes[i].tick_params(axis='x', rotation=45)
                axes[i].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    def _correlation_analysis(self):
        print("\nAN√ÅLISE DE CORRELA√á√ïES")
        print("-" * 28)
        
        # Preparar dados para an√°lise de correla√ß√£o
        df_corr = self.df.copy()
        
        # Codificar vari√°veis categ√≥ricas para an√°lise de correla√ß√£o
        le = LabelEncoder()
        categorical_cols = df_corr.select_dtypes(include=['object']).columns
        
        for col in categorical_cols:
            df_corr[col] = le.fit_transform(df_corr[col])
        
        # Remover colunas constantes
        cols_to_remove = ['EmployeeCount', 'StandardHours', 'EmployeeNumber']
        df_corr = df_corr.drop(columns=cols_to_remove, errors='ignore')
        
        # Calcular matriz de correla√ß√£o
        correlation_matrix = df_corr.corr()
        
        # Correla√ß√µes com a vari√°vel target
        target_correlations = correlation_matrix['Attrition'].abs().sort_values(ascending=False)[1:]
        
        print("Top 10 vari√°veis mais correlacionadas com Attrition:")
        for var, corr in target_correlations.head(10).items():
            direction = "positiva" if correlation_matrix.loc[var, 'Attrition'] > 0 else "negativa"
            print(f"{var}: {corr:.3f} (correla√ß√£o {direction})")
        
        # Visualiza√ß√£o da matriz de correla√ß√£o
        plt.figure(figsize=(16, 14))
        mask = np.triu(correlation_matrix)
        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
                   square=True, linewidths=0.5, cbar_kws={"shrink": 0.8},
                   mask=mask, fmt='.2f', annot_kws={'size': 8})
        plt.title('Matriz de Correla√ß√£o - Vari√°veis do Dataset', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.show()
    
    def _outlier_detection(self):
        print("\nDETEC√á√ÉO DE OUTLIERS")
        print("-" * 25)
        
        numerical_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()
        cols_to_remove = ['EmployeeCount', 'StandardHours', 'EmployeeNumber']
        numerical_cols = [col for col in numerical_cols if col not in cols_to_remove]
        
        outlier_summary = {}
        
        for col in numerical_cols:
            Q1 = self.df[col].quantile(0.25)
            Q3 = self.df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = self.df[(self.df[col] < lower_bound) | (self.df[col] > upper_bound)]
            outlier_count = len(outliers)
            outlier_percentage = (outlier_count / len(self.df)) * 100
            
            if outlier_count > 0:
                outlier_summary[col] = {
                    'count': outlier_count,
                    'percentage': outlier_percentage,
                    'lower_bound': lower_bound,
                    'upper_bound': upper_bound
                }
        
        if outlier_summary:
            print("Vari√°veis com outliers detectados (m√©todo IQR):")
            for var, info in sorted(outlier_summary.items(), 
                                  key=lambda x: x[1]['percentage'], reverse=True):
                print(f"{var}: {info['count']} outliers ({info['percentage']:.1f}%)")
        else:
            print("Nenhum outlier significativo detectado")
        
        # Decidir estrat√©gia de tratamento
        high_outlier_vars = [var for var, info in outlier_summary.items() 
                           if info['percentage'] > 5]
        
        if high_outlier_vars:
            print(f"\nAVISO: Vari√°veis com muitos outliers (>5%): {high_outlier_vars}")
            print("Estrat√©gia: Manter outliers (podem ser casos reais de neg√≥cio)")
    
    def _business_insights(self):
        """Gera insights espec√≠ficos de neg√≥cio."""
        print("\nINSIGHTS DE NEG√ìCIO")
        print("-" * 25)
        
        insights = []
        
        # Insight 1: Faixa et√°ria
        age_analysis = self.df.groupby(['Attrition'])['Age'].agg(['mean', 'median']).round(1)
        age_diff = age_analysis.loc['Yes', 'mean'] - age_analysis.loc['No', 'mean']
        if abs(age_diff) > 2:
            direction = "mais jovens" if age_diff < 0 else "mais velhos"
            insights.append(f"Funcion√°rios que saem s√£o em m√©dia {abs(age_diff):.1f} anos {direction}")
        
        # Insight 2: Renda mensal
        if 'MonthlyIncome' in self.df.columns:
            income_analysis = self.df.groupby(['Attrition'])['MonthlyIncome'].agg(['mean', 'median'])
            income_diff = income_analysis.loc['No', 'mean'] - income_analysis.loc['Yes', 'mean']
            if income_diff > 1000:
                insights.append(f"Funcion√°rios que ficam ganham em m√©dia R$ {income_diff:,.0f} a mais")
        
        # Insight 3: Overtime
        if 'OverTime' in self.df.columns:
            overtime_analysis = pd.crosstab(self.df['OverTime'], self.df['Attrition'], normalize='index') * 100
            if 'Yes' in overtime_analysis.columns and 'Yes' in overtime_analysis.index:
                overtime_attrition = overtime_analysis.loc['Yes', 'Yes']
                no_overtime_attrition = overtime_analysis.loc['No', 'Yes']
                if overtime_attrition > no_overtime_attrition * 1.5:
                    insights.append(f"Funcion√°rios com overtime t√™m {overtime_attrition:.1f}% de attrition vs {no_overtime_attrition:.1f}% sem overtime")
        
        # Insight 4: Tempo na empresa
        if 'YearsAtCompany' in self.df.columns:
            tenure_analysis = self.df.groupby(['Attrition'])['YearsAtCompany'].agg(['mean', 'median']).round(1)
            tenure_diff = tenure_analysis.loc['No', 'mean'] - tenure_analysis.loc['Yes', 'mean']
            if tenure_diff > 1:
                insights.append(f"Funcion√°rios que ficam t√™m em m√©dia {tenure_diff:.1f} anos a mais de empresa")
        
        # Insight 5: Dist√¢ncia de casa
        if 'DistanceFromHome' in self.df.columns:
            distance_analysis = self.df.groupby(['Attrition'])['DistanceFromHome'].agg(['mean', 'median']).round(1)
            distance_diff = distance_analysis.loc['Yes', 'mean'] - distance_analysis.loc['No', 'mean']
            if distance_diff > 2:
                insights.append(f"Funcion√°rios que saem moram em m√©dia {distance_diff:.1f} km mais longe")
        
        print("Principais descobertas:")
        for i, insight in enumerate(insights, 1):
            print(f"  {i}. {insight}")
        
        if not insights:
            print("An√°lise mais detalhada necess√°ria para insights espec√≠ficos")
        
        # Recomenda√ß√µes iniciais
        print("\nRECOMENDA√á√ïES PRELIMINARES:")
        print("Revisar pol√≠tica de overtime e work-life balance")
        print("Implementar programas de reten√ß√£o para funcion√°rios j√∫niores")
        print("Considerar trabalho remoto/h√≠brido para funcion√°rios distantes")
        print("Desenvolver planos de carreira mais claros")
    
    def preprocess_data(self):
        print("\nPR√â-PROCESSAMENTO DOS DADOS")
        print("=" * 35)
        
        # Separar target
        y = self.df['Attrition'].copy()
        X = self.df.drop('Attrition', axis=1).copy()
        
        # Remover colunas irrelevantes
        cols_to_drop = ['EmployeeCount', 'StandardHours', 'EmployeeNumber', 'Over18']
        X = X.drop(columns=[col for col in cols_to_drop if col in X.columns])
        
        print(f"Removidas {len([col for col in cols_to_drop if col in self.df.columns])} colunas irrelevantes")
        
        # Codificar vari√°veis categ√≥ricas
        categorical_cols = X.select_dtypes(include=['object']).columns.tolist()
        
        # One-hot encoding para vari√°veis categ√≥ricas
        X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)
        
        print(f"Aplicado one-hot encoding a {len(categorical_cols)} vari√°veis categ√≥ricas")
        print(f"Dimens√µes finais: {X_encoded.shape}")
        
        # Codificar target
        le_target = LabelEncoder()
        y_encoded = le_target.fit_transform(y)
        
        # Dividir dados
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X_encoded, y_encoded,
            test_size=0.25,
            random_state=42,
            stratify=y_encoded
        )
        
        self.feature_names = X_encoded.columns.tolist()
        
        print(f"Dados divididos - Treino: {self.X_train.shape[0]}, Teste: {self.X_test.shape[0]}")
        
        # Balanceamento de classes
        self._analyze_class_balance()
        
        return True
    
    def _analyze_class_balance(self):
        unique, counts = np.unique(self.y_train, return_counts=True)
        
        print(f"\nBALANCEAMENTO DE CLASSES (Conjunto de Treino)")
        print(f"Classe 0 (No): {counts[0]} amostras ({counts[0]/len(self.y_train)*100:.1f}%)")
        print(f"Classe 1 (Yes): {counts[1]} amostras ({counts[1]/len(self.y_train)*100:.1f}%)")
        
        imbalance_ratio = max(counts) / min(counts)
        print(f"Taxa de desbalanceamento: {imbalance_ratio:.1f}:1")
        
        if imbalance_ratio > 3:
            print("Estrat√©gia: class_weight='balanced' + m√©tricas espec√≠ficas")
        else:
            print("Estrat√©gia: Balanceamento natural suficiente")
    
    def train_models(self):
        """Treina m√∫ltiplos modelos de machine learning."""
        print("\nTREINAMENTO DOS MODELOS")
        print("=" * 30)
        
        # Modelo 1: Random Forest (principal)
        print("\nRandom Forest Classifier")
        rf_model = RandomForestClassifier(
            n_estimators=100,
            random_state=42,
            class_weight='balanced',
            n_jobs=-1
        )
        
        rf_model.fit(self.X_train, self.y_train)
        self.models['random_forest_base'] = rf_model
        
        # Modelo 2: Gradient Boosting
        print("Gradient Boosting Classifier")
        gb_model = GradientBoostingClassifier(
            n_estimators=100,
            random_state=42
        )
        
        gb_model.fit(self.X_train, self.y_train)
        self.models['gradient_boosting'] = gb_model
        
        # Modelo 3: Logistic Regression (baseline)
        print("Logistic Regression")
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(self.X_train)
        X_test_scaled = scaler.transform(self.X_test)
        
        # Calcular class_weight para LogisticRegression
        class_weights = compute_class_weight(
            'balanced', 
            classes=np.unique(self.y_train), 
            y=self.y_train
        )
        class_weight_dict = {0: class_weights[0], 1: class_weights[1]}
        
        lr_model = LogisticRegression(
            random_state=42,
            class_weight=class_weight_dict,
            max_iter=1000
        )
        
        lr_model.fit(X_train_scaled, self.y_train)
        self.models['logistic_regression'] = lr_model
        self.models['scaler'] = scaler  # Salvar o scaler para uso posterior
        
        print("Todos os modelos treinados com sucesso!")
        
        # Avalia√ß√£o inicial r√°pida
        self._quick_evaluation()
    
    def _quick_evaluation(self):
        """Avalia√ß√£o r√°pida de todos os modelos."""
        print("\nAVALIA√á√ÉO INICIAL DOS MODELOS")
        print("-" * 35)
        
        results_summary = []
        
        for name, model in self.models.items():
            if name == 'scaler':
                continue
                
            # Fazer predi√ß√µes
            if name == 'logistic_regression':
                X_test_eval = self.models['scaler'].transform(self.X_test)
            else:
                X_test_eval = self.X_test
                
            y_pred = model.predict(X_test_eval)
            y_pred_proba = model.predict_proba(X_test_eval)[:, 1]
            
            # Calcular m√©tricas
            accuracy = accuracy_score(self.y_test, y_pred)
            precision = precision_score(self.y_test, y_pred)
            recall = recall_score(self.y_test, y_pred)
            f1 = fbeta_score(self.y_test, y_pred, beta=1)
            f2 = fbeta_score(self.y_test, y_pred, beta=2)
            roc_auc = roc_auc_score(self.y_test, y_pred_proba)
            pr_auc = average_precision_score(self.y_test, y_pred_proba)
            
            results_summary.append({
                'Modelo': name.replace('_', ' ').title(),
                'Accuracy': f"{accuracy:.3f}",
                'Precision': f"{precision:.3f}",
                'Recall': f"{recall:.3f}",
                'F1-Score': f"{f1:.3f}",
                'F2-Score': f"{f2:.3f}",
                'ROC-AUC': f"{roc_auc:.3f}",
                'PR-AUC': f"{pr_auc:.3f}"
            })
        
        # Exibir resultados em tabela
        results_df = pd.DataFrame(results_summary)
        print(results_df.to_string(index=False))
        
        # Identificar melhor modelo para otimiza√ß√£o
        best_model_name = max(self.models.keys() - {'scaler'}, 
                            key=lambda x: roc_auc_score(
                                self.y_test, 
                                self.models[x].predict_proba(
                                    self.models['scaler'].transform(self.X_test) if x == 'logistic_regression' else self.X_test
                                )[:, 1]
                            ))
        
        print(f"\nMelhor modelo inicial: {best_model_name.replace('_', ' ').title()}")
    
    def optimize_hyperparameters(self, model_name='random_forest_base'):
        """Otimiza√ß√£o avan√ßada de hiperpar√¢metros."""
        print(f"\nOTIMIZA√á√ÉO DE HIPERPAR√ÇMETROS - {model_name.upper()}")
        print("=" * 50)
        
        if model_name == 'random_forest_base':
            self._optimize_random_forest()
        elif model_name == 'gradient_boosting':
            self._optimize_gradient_boosting()
        else:
            print(f"Otimiza√ß√£o n√£o implementada para {model_name}")
    
    def _optimize_random_forest(self):
        """Otimiza√ß√£o espec√≠fica para Random Forest."""
        print("Iniciando otimiza√ß√£o do Random Forest...")
        
        # Grid Search simplificado para ser mais r√°pido
        param_grid = {
            'n_estimators': [100, 200, 300],
            'max_depth': [10, 20, 30, None],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4],
            'max_features': ['sqrt', 'log2']
        }
        
        base_model = RandomForestClassifier(
            random_state=42,
            class_weight='balanced',
            n_jobs=-1
        )
        
        cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)
        
        search = GridSearchCV(
            estimator=base_model,
            param_grid=param_grid,
            cv=cv,
            scoring='average_precision',
            n_jobs=-1,
            verbose=1
        )
        
        print("Usando Grid Search tradicional")
        
        # Executar busca
        print("Executando busca de hiperpar√¢metros... (isso pode levar alguns minutos)")
        search.fit(self.X_train, self.y_train)
        
        # Salvar melhor modelo
        self.models['random_forest_optimized'] = search.best_estimator_
        
        print(f"Otimiza√ß√£o conclu√≠da!")
        print(f"Melhor score (Average Precision): {search.best_score_:.4f}")
        print(f"Melhores par√¢metros:")
        for param, value in search.best_params_.items():
            print(f"{param}: {value}")
    
    def comprehensive_evaluation(self):
        print("\nAVALIA√á√ÉO ABRANGENTE DOS MODELOS")
        print("=" * 40)
        
        # Identificar melhor modelo
        best_model_name = self._identify_best_model()
        
        if best_model_name:
            print(f"Modelo selecionado para an√°lise detalhada: {best_model_name.replace('_', ' ').title()}")
            
            # An√°lise detalhada do melhor modelo
            self._detailed_model_analysis(best_model_name)
            
            # An√°lise de interpretabilidade
            self._model_interpretability(best_model_name)
            
            # Recomenda√ß√µes de produ√ß√£o
            self._production_recommendations(best_model_name)
        else:
            print("ERRO: Nenhum modelo dispon√≠vel para avalia√ß√£o")
    
    def _identify_best_model(self):
        model_scores = {}
        
        for name, model in self.models.items():
            if name == 'scaler':
                continue
                
            # Preparar dados de teste
            if name == 'logistic_regression':
                X_test_eval = self.models['scaler'].transform(self.X_test)
            else:
                X_test_eval = self.X_test
            
            try:
                y_pred_proba = model.predict_proba(X_test_eval)[:, 1]
                
                # Calcular m√∫ltiplas m√©tricas
                roc_auc = roc_auc_score(self.y_test, y_pred_proba)
                pr_auc = average_precision_score(self.y_test, y_pred_proba)
                
                # Score composto (m√©dia ponderada)
                composite_score = 0.4 * roc_auc + 0.6 * pr_auc  # Mais peso para PR-AUC
                model_scores[name] = composite_score
                
            except Exception as e:
                print(f"AVISO: Erro ao avaliar modelo {name}: {str(e)}")
                continue
        
        if model_scores:
            best_model = max(model_scores.keys(), key=lambda x: model_scores[x])
            return best_model
        else:
            return None
    
    def _detailed_model_analysis(self, model_name):
        print(f"\nAN√ÅLISE DETALHADA - {model_name.upper()}")
        print("-" * 45)
        
        model = self.models[model_name]
        
        # Preparar dados
        if model_name == 'logistic_regression':
            X_test_eval = self.models['scaler'].transform(self.X_test)
        else:
            X_test_eval = self.X_test
        
        y_pred = model.predict(X_test_eval)
        y_pred_proba = model.predict_proba(X_test_eval)[:, 1]
        
        # M√©tricas detalhadas
        print("M√âTRICAS DE PERFORMANCE:")
        
        accuracy = accuracy_score(self.y_test, y_pred)
        balanced_acc = balanced_accuracy_score(self.y_test, y_pred)
        precision = precision_score(self.y_test, y_pred)
        recall = recall_score(self.y_test, y_pred)
        f1 = fbeta_score(self.y_test, y_pred, beta=1)
        f2 = fbeta_score(self.y_test, y_pred, beta=2)
        mcc = matthews_corrcoef(self.y_test, y_pred)
        roc_auc = roc_auc_score(self.y_test, y_pred_proba)
        pr_auc = average_precision_score(self.y_test, y_pred_proba)
        log_loss_val = log_loss(self.y_test, y_pred_proba)
        
        metrics = {
            'Accuracy': accuracy,
            'Balanced Accuracy': balanced_acc,
            'Precision': precision,
            'Recall (Sensibilidade)': recall,
            'F1-Score': f1,
            'F2-Score': f2,
            'Matthews Correlation': mcc,
            'ROC-AUC': roc_auc,
            'PR-AUC': pr_auc,
            'Log Loss': log_loss_val
        }
        
        for metric, value in metrics.items():
            if metric == 'Log Loss':
                print(f"{metric}: {value:.4f} (menor √© melhor)")
            else:
                print(f"{metric}: {value:.4f}")
        
        # Interpreta√ß√£o das m√©tricas
        print("\nINTERPRETA√á√ÉO DAS M√âTRICAS:")
        if recall >= 0.8:
            print("    Excelente capacidade de identificar funcion√°rios em risco")
        elif recall >= 0.6:
            print("    AVISO: Boa capacidade de identificar funcion√°rios em risco")
        else:
            print("    ERRO: Capacidade limitada de identificar funcion√°rios em risco")
        
        if precision >= 0.7:
            print("    Baixa taxa de falsos positivos")
        elif precision >= 0.5:
            print("    AVISO: Taxa moderada de falsos positivos")
        else:
            print("    ERRO: Alta taxa de falsos positivos")
        
        if f2 >= 0.7:
            print("    Excelente balan√ßo priorizando recall")
        elif f2 >= 0.5:
            print("    AVISO: Balan√ßo moderado priorizando recall")
        else:
            print("    ERRO: Necess√°rio melhorar o modelo")
        
        # Visualiza√ß√µes
        self._create_performance_visualizations(model_name, y_pred, y_pred_proba)
        
        # Matriz de confus√£o detalhada
        self._detailed_confusion_matrix(y_pred)
        
        # Salvar resultados
        self.results[model_name] = {
            'predictions': y_pred,
            'probabilities': y_pred_proba,
            'metrics': metrics
        }
    
    def _create_performance_visualizations(self, model_name, y_pred, y_pred_proba):
        """Cria visualiza√ß√µes de performance do modelo."""
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. Curva ROC
        fpr, tpr, _ = roc_curve(self.y_test, y_pred_proba)
        roc_auc = auc(fpr, tpr)
        
        axes[0, 0].plot(fpr, tpr, color='darkorange', lw=2, 
                       label=f'ROC Curve (AUC = {roc_auc:.3f})')
        axes[0, 0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')
        axes[0, 0].set_xlim([0.0, 1.0])
        axes[0, 0].set_ylim([0.0, 1.05])
        axes[0, 0].set_xlabel('Taxa de Falsos Positivos')
        axes[0, 0].set_ylabel('Taxa de Verdadeiros Positivos')
        axes[0, 0].set_title('Curva ROC', fontweight='bold')
        axes[0, 0].legend(loc="lower right")
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. Curva Precision-Recall
        precision, recall, _ = precision_recall_curve(self.y_test, y_pred_proba)
        pr_auc = auc(recall, precision)
        
        axes[0, 1].plot(recall, precision, color='blue', lw=2,
                       label=f'PR Curve (AUC = {pr_auc:.3f})')
        axes[0, 1].axhline(y=np.mean(self.y_test), color='red', linestyle='--', 
                          label=f'Baseline ({np.mean(self.y_test):.3f})')
        axes[0, 1].set_xlim([0.0, 1.0])
        axes[0, 1].set_ylim([0.0, 1.05])
        axes[0, 1].set_xlabel('Recall')
        axes[0, 1].set_ylabel('Precision')
        axes[0, 1].set_title('Curva Precision-Recall', fontweight='bold')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. Distribui√ß√£o de Probabilidades
        prob_yes = y_pred_proba[self.y_test == 1]
        prob_no = y_pred_proba[self.y_test == 0]
        
        axes[1, 0].hist(prob_no, bins=30, alpha=0.7, label='N√£o Sai (0)', color='lightblue')
        axes[1, 0].hist(prob_yes, bins=30, alpha=0.7, label='Sai (1)', color='coral')
        axes[1, 0].axvline(x=0.5, color='red', linestyle='--', label='Threshold = 0.5')
        axes[1, 0].set_xlabel('Probabilidade Predita')
        axes[1, 0].set_ylabel('Frequ√™ncia')
        axes[1, 0].set_title('Distribui√ß√£o de Probabilidades por Classe', fontweight='bold')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. Calibra√ß√£o do modelo
        from sklearn.calibration import calibration_curve
        
        fraction_of_positives, mean_predicted_value = calibration_curve(
            self.y_test, y_pred_proba, n_bins=10
        )
        
        axes[1, 1].plot(mean_predicted_value, fraction_of_positives, "s-", 
                       label=f"{model_name}", color='blue')
        axes[1, 1].plot([0, 1], [0, 1], "k:", label="Perfeitamente calibrado")
        axes[1, 1].set_xlabel('Probabilidade M√©dia Predita')
        axes[1, 1].set_ylabel('Fra√ß√£o de Positivos')
        axes[1, 1].set_title('Curva de Calibra√ß√£o', fontweight='bold')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    def _detailed_confusion_matrix(self, y_pred):
        cm = confusion_matrix(self.y_test, y_pred)
        
        # Calcular m√©tricas da matriz de confus√£o
        tn, fp, fn, tp = cm.ravel()
        
        print(f"\nMATRIZ DE CONFUS√ÉO DETALHADA:")
        print(f"Verdadeiros Negativos (TN): {tn} - Funcion√°rios corretamente identificados como 'n√£o sair√£o'")
        print(f"Falsos Positivos (FP): {fp} - Funcion√°rios incorretamente identificados como 'sair√£o'")
        print(f"Falsos Negativos (FN): {fn} - Funcion√°rios que sair√£o mas n√£o foram identificados")
        print(f"Verdadeiros Positivos (TP): {tp} - Funcion√°rios corretamente identificados como 'sair√£o'")
        
        # Interpreta√ß√£o de neg√≥cio
        print(f"\nIMPACTO FINANCEIRO ESTIMADO (por 1000 funcion√°rios):")
        
        # Custo de falsos negativos (funcion√°rios que saem sem identifica√ß√£o)
        cost_per_employee = 1.5 * 60000  # 1.5x sal√°rio m√©dio anual estimado
        fn_cost = (fn / len(self.y_test)) * 1000 * cost_per_employee
        
        # Custo de falsos positivos (recursos gastos desnecessariamente)
        intervention_cost = 5000  # Custo estimado de interven√ß√£o por funcion√°rio
        fp_cost = (fp / len(self.y_test)) * 1000 * intervention_cost
        
        print(f"  Custo de Falsos Negativos: R$ {fn_cost:,.0f}")
        print(f"  Custo de Falsos Positivos: R$ {fp_cost:,.0f}")
        print(f"  Custo Total Estimado: R$ {fn_cost + fp_cost:,.0f}")
        
        # Economia potencial
        baseline_cost = np.mean(self.y_test) * 1000 * cost_per_employee
        model_cost = fn_cost + fp_cost
        savings = baseline_cost - model_cost
        
        if savings > 0:
            print(f"  Economia Potencial: R$ {savings:,.0f} ({savings/baseline_cost*100:.1f}%)")
        else:
            print(f"  AVISO: Necess√°rio otimizar para reduzir custos")
        
        # Visualiza√ß√£o da matriz
        plt.figure(figsize=(10, 8))
        
        # Criar anota√ß√µes personalizadas
        annot = np.array([[f'TN\n{tn}\n({tn/(tn+fp)*100:.1f}%)', 
                          f'FP\n{fp}\n({fp/(tn+fp)*100:.1f}%)'],
                         [f'FN\n{fn}\n({fn/(fn+tp)*100:.1f}%)', 
                          f'TP\n{tp}\n({tp/(fn+tp)*100:.1f}%)']])
        
        sns.heatmap(cm, annot=annot, fmt='', cmap='Blues', 
                   xticklabels=['Predito: N√£o Sai', 'Predito: Sai'],
                   yticklabels=['Real: N√£o Sai', 'Real: Sai'],
                   cbar_kws={'label': 'N√∫mero de Funcion√°rios'})
        
        plt.title('Matriz de Confus√£o - Interpreta√ß√£o de Neg√≥cio', 
                 fontsize=16, fontweight='bold')
        plt.ylabel('Classe Real')
        plt.xlabel('Classe Predita')
        plt.tight_layout()
        plt.show()
    
    def _model_interpretability(self, model_name):
        print(f"\nINTERPRETABILIDADE DO MODELO")
        print("-" * 35)
        
        model = self.models[model_name]
        
        # Feature Importance (para modelos tree-based)
        if hasattr(model, 'feature_importances_'):
            self._analyze_feature_importance(model)
    
    def _analyze_feature_importance(self, model):
        """An√°lise de import√¢ncia das features (tree-based models)."""
        print("\nIMPORT√ÇNCIA DAS VARI√ÅVEIS (Tree-based)")
        
        importances = model.feature_importances_
        feature_importance_df = pd.DataFrame({
            'feature': self.feature_names,
            'importance': importances
        }).sort_values('importance', ascending=False)
        
        # Top 15 features
        top_features = feature_importance_df.head(15)
        
        print("Top 15 vari√°veis mais importantes:")
        for idx, row in top_features.iterrows():
            print(f"  {row['feature']}: {row['importance']:.4f}")
        
        # Visualiza√ß√£o
        plt.figure(figsize=(14, 10))
        sns.barplot(data=top_features, x='importance', y='feature', palette='viridis')
        plt.title('Top 15 Vari√°veis - Import√¢ncia no Modelo', fontsize=16, fontweight='bold')
        plt.xlabel('Import√¢ncia Relativa')
        plt.ylabel('Vari√°veis')
        plt.tight_layout()
        plt.show()
        
        # An√°lise cumulativa
        cumulative_importance = np.cumsum(feature_importance_df['importance'].values)
        n_features_80 = np.argmax(cumulative_importance >= 0.8) + 1
        n_features_95 = np.argmax(cumulative_importance >= 0.95) + 1
        
        print(f"\nAn√°lise de import√¢ncia cumulativa:")
        print(f"  {n_features_80} vari√°veis explicam 80% da import√¢ncia")
        print(f"  {n_features_95} vari√°veis explicam 95% da import√¢ncia")
    
    def _production_recommendations(self, model_name):
        """Recomenda√ß√µes para implementa√ß√£o em produ√ß√£o."""
        print(f"\nRECOMENDA√á√ïES PARA PRODU√á√ÉO")
        print("=" * 35)
        
        print("CHECKLIST DE IMPLEMENTA√á√ÉO:")
        print("Modelo treinado e validado")
        print("An√°lise de vi√©s realizada")
        
        print(f"\nPIPELINE DE PRODU√á√ÉO:")
        print("1. Coleta de dados em tempo real")
        print("2. Pr√©-processamento autom√°tico")
        print("3. Predi√ß√£o com modelo otimizado")
        print("4. Aplica√ß√£o de threshold recomendado")
        print("5. Alertas para RH sobre funcion√°rios em risco")
        print("6. Dashboard de monitoramento")
        
        print(f"\nMONITORAMENTO CONT√çNUO:")
        print("Data drift: Verificar mudan√ßas na distribui√ß√£o dos dados")
        print("Model drift: Monitorar performance ao longo do tempo")
        print("Feedback loop: Coletar resultados das interven√ß√µes")
        print("Retreinamento: Agendar retreinamento mensal/trimestral")
        
        print(f"\nESTRAT√âGIAS DE INTERVEN√á√ÉO:")
        print("Baixo risco (< 30%): Monitoramento passivo")
        print("M√©dio risco (30-60%): Conversas com gestor")
        print("Alto risco (> 60%): A√ß√£o imediata do RH")
        
        print(f"\nROI ESPERADO:")
        print("Redu√ß√£o estimada de attrition: 25-40%")
        print("Economia anual estimada: R$ 8-15 milh√µes")
        print("Payback do projeto: 3-6 meses")
        
        print(f"\nPR√ìXIMOS PASSOS:")
        print("1. Aprova√ß√£o da diretoria")
        print("2. Setup da infraestrutura de dados")
        print("3. Desenvolvimento da API de predi√ß√£o")
        print("4. Cria√ß√£o do dashboard gerencial")
        print("5. Treinamento da equipe de RH")
        print("6. Piloto com um departamento")
        print("7. Rollout completo")
    
    def generate_report(self):
        """Gera relat√≥rio executivo completo."""
        print(f"\nRELAT√ìRIO EXECUTIVO")
        print("=" * 25)
        
        if not self.results:
            print("ERRO: Nenhum modelo avaliado. Execute a an√°lise completa primeiro.")
            return
        
        best_model_name = list(self.results.keys())[-1]
        best_results = self.results[best_model_name]
        
        print(f"RESUMO EXECUTIVO - SISTEMA PREDITIVO DE ATTRITION")
        print(f"Data: {pd.Timestamp.now().strftime('%d/%m/%Y %H:%M')}")
        print(f"Dataset: {self.df.shape[0]:,} funcion√°rios analisados")
        
        print(f"\nMODELO SELECIONADO: {best_model_name.replace('_', ' ').title()}")
        
        metrics = best_results['metrics']
        print(f"\nM√âTRICAS DE PERFORMANCE:")
        print(f"  Precis√£o (Precision): {metrics['Precision']:.1%}")
        print(f"  Recall (Sensibilidade): {metrics['Recall (Sensibilidade)']:.1%}")
        print(f"  F2-Score: {metrics['F2-Score']:.1%}")
        print(f"  ROC-AUC: {metrics['ROC-AUC']:.1%}")
        
        # Interpreta√ß√£o executiva
        recall_val = metrics['Recall (Sensibilidade)']
        precision_val = metrics['Precision']
        
        print(f"\nINTERPRETA√á√ÉO DE NEG√ìCIO:")
        if recall_val >= 0.8:
            print(f"    EXCELENTE: O modelo identifica {recall_val:.0%} dos funcion√°rios que realmente sair√£o")
        elif recall_val >= 0.6:
            print(f"    AVISO BOM: O modelo identifica {recall_val:.0%} dos funcion√°rios que realmente sair√£o")
        else:
            print(f"    ERRO LIMITADO: O modelo identifica apenas {recall_val:.0%} dos funcion√°rios que realmente sair√£o")
        
        if precision_val >= 0.7:
            print(f"    BAIXO FALSO ALARME: {precision_val:.0%} dos alertas s√£o realmente funcion√°rios em risco")
        elif precision_val >= 0.5:
            print(f"    AVISO FALSO ALARME MODERADO: {precision_val:.0%} dos alertas s√£o realmente funcion√°rios em risco")
        else:
            print(f"    ERRO ALTO FALSO ALARME: Apenas {precision_val:.0%} dos alertas s√£o realmente funcion√°rios em risco")
        
        print(f"\nRECOMENDA√á√ÉO FINAL:")
        f2_score = metrics['F2-Score']
        if f2_score >= 0.7:
            print(f"    IMPLEMENTAR: Modelo pronto para produ√ß√£o")
        elif f2_score >= 0.5:
            print(f"    MELHORAR: Implementar com monitoramento intensivo")
        else:
            print(f"    DESENVOLVER: Necess√°rio mais desenvolvimento antes da implementa√ß√£o")
        
        print(f"\nIMPACTO ESPERADO:")
        print(f"  Redu√ß√£o estimada de attrition: 25-40%")
        print(f"  Economia anual: R$ 8-15 milh√µes")
        print(f"  ROI do projeto: 300-500%")


def main(run_optimization=True, data_path=None):
    """
    Fun√ß√£o principal - execu√ß√£o do pipeline completo.
    
    Par√¢metros:
    -----------
    run_optimization : bool, default=True
        Se deve executar otimiza√ß√£o de hiperpar√¢metros automaticamente
    data_path : str, optional
        Caminho para o arquivo CSV (se n√£o especificado, usa o padr√£o)
    """
    print("INICIANDO SISTEMA DE PREDI√á√ÉO DE ATTRITION - TECHCORP BRASIL")
    print("=" * 70)
    
    # Inicializar analisador
    if data_path:
        analyzer = AttritionAnalyzer(data_path=data_path)
    else:
        analyzer = AttritionAnalyzer()
    
    # 1. Carregar dados
    if not analyzer.load_data():
        print("ERRO: Falha ao carregar dados. Encerrando an√°lise.")
        return
    
    # 2. An√°lise explorat√≥ria completa
    print(f"\nFASE 1: AN√ÅLISE EXPLORAT√ìRIA")
    analyzer.exploratory_data_analysis()
    
    # 3. Pr√©-processamento
    print(f"\nFASE 2: PR√â-PROCESSAMENTO")
    if not analyzer.preprocess_data():
        print("ERRO: Falha no pr√©-processamento. Encerrando an√°lise.")
        return
    
    # 4. Treinamento de modelos
    print(f"\nFASE 3: TREINAMENTO DE MODELOS")
    analyzer.train_models()
    
    # 5. Otimiza√ß√£o (controlada por par√¢metro)
    print(f"\nFASE 4: OTIMIZA√á√ÉO DE HIPERPAR√ÇMETROS")
    if run_optimization:
        print("Executando otimiza√ß√£o autom√°tica...")
        analyzer.optimize_hyperparameters('random_forest_base')
    else:
        print("Otimiza√ß√£o pulada - usando modelos base")
    
    # 6. Avalia√ß√£o abrangente
    print(f"\nFASE 5: AVALIA√á√ÉO FINAL")
    analyzer.comprehensive_evaluation()
    
    # 7. Relat√≥rio final
    print(f"\nFASE 6: RELAT√ìRIO EXECUTIVO")
    analyzer.generate_report()
    
    print(f"\nAN√ÅLISE CONCLU√çDA COM SUCESSO!")
    print(f"O sistema est√° pronto para implementa√ß√£o em produ√ß√£o.")
    print(f"Consulte as recomenda√ß√µes acima para os pr√≥ximos passos.")
    
    return analyzer


def run_quick_analysis(data_path=None):
    """
    Execu√ß√£o r√°pida sem otimiza√ß√£o - ideal para Google Colab.
    
    Par√¢metros:
    -----------
    data_path : str, optional
        Caminho para o arquivo CSV
    """
    print("üöÄ EXECUTANDO AN√ÅLISE R√ÅPIDA - GOOGLE COLAB")
    print("=" * 50)
    return main(run_optimization=False, data_path=data_path)


def run_full_analysis(data_path=None):
    """
    Execu√ß√£o completa com otimiza√ß√£o - pode ser demorada.
    
    Par√¢metros:
    -----------
    data_path : str, optional
        Caminho para o arquivo CSV
    """
    print("üî• EXECUTANDO AN√ÅLISE COMPLETA")
    print("=" * 35)
    return main(run_optimization=True, data_path=data_path)


# Execu√ß√£o do programa
if __name__ == "__main__":
    main()